{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec21cb4-7df7-4b0d-b3dc-3e15c0c8c5d4",
   "metadata": {},
   "source": [
    "## Notebook: factors influencing precision\n",
    "\n",
    "In this notebook we will compute and plot confidence intervals for a constant velocity model.\n",
    "\n",
    "Click {fa}`rocket` --> {guilabel}`Live Code` on the top right corner of this screen and then wait until all cells are executed. You will only have to run the code, and optionally may want to change some variables.\n",
    "\n",
    "**Learning objectives:**\n",
    "- evaluate the influence of changing some parameters: number of observations, standard deviation and sampling interval.\n",
    "- discuss why the changes occur.\n",
    "- discuss and understand the importance of correctly assessing the confidence intervals.\n",
    "\n",
    "The code cells to import packages, with the functions used to apply BLUE and calculate the confidence intervals, and the <code>plot_all</code> function are hidden. Download the notebook to see the complete notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9efab-0d01-45ed-bc7a-05996cb5e3bf",
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import micropip\n",
    "await micropip.install(\"ipywidgets\")\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216fef91-b406-4ea5-a301-9bc2dc6e320f",
   "metadata": {},
   "source": [
    "## Observation model\n",
    "\n",
    "The code cell below sets up our problem in three steps:\n",
    "1. Set the observation model using the time when the observations were taken (epoch) to create our $\\mathrm{A}$-matrix\n",
    "2. Artificially create our random observations, `y`, with error `e`\n",
    "3. Create the $\\mathrm{A}$-matrix of our predictions\n",
    "\n",
    "The simulated set of observations uses the `random.seed` method to ensure that the realizations in the random sample are always the sam. This is to ensure that everyone gets the same result; it is still a random sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fca47-5add-4d33-a4d4-a5f5bddc48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.vstack([1,3,3.5,5,5.5,7,9,10,10.5,\n",
    "               11.5,13,14,16,16.5,18,19,\n",
    "               20,22.5,24,25])\n",
    "m = len(t)\n",
    "A = np.hstack((np.ones((m,1)),t))\n",
    "sigma = 2\n",
    "\n",
    "np.random.seed(1613353294)\n",
    "e = np.random.normal(0, sigma, m)\n",
    "xo = [3,0.3]\n",
    "y = A @ xo + e\n",
    "\n",
    "m_pred = 30\n",
    "t_pred = np.arange(1,m_pred+1)\n",
    "A_pred = np.column_stack((np.ones(m_pred), t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294e2f5",
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def BLUE(A, y, Sigma_Y):\n",
    "    \"\"\" \n",
    "    Function to calculate the Best Linear Unbiased Estimator\n",
    "    Output: \n",
    "    xhat        estimated parameters\n",
    "    Sigma_Xhat  covariance matrix of estimated parameters\n",
    "    yhat        adjusted observations\n",
    "    \"\"\"\n",
    "    inv_Sigma_Y = np.linalg.inv(Sigma_Y)\n",
    "    Sigma_Xhat = np.linalg.inv(A.T @ inv_Sigma_Y @ A)\n",
    "    xhat = Sigma_Xhat @ A.T @ inv_Sigma_Y @ y\n",
    "    yhat = A @ xhat\n",
    "    return xhat, Sigma_Xhat, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ae36d",
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def BLUE_predict(A_pred, xhat, Sigma_Xhat):\n",
    "    \"\"\" \n",
    "    Function to calculate the fitted model (yhat) incl. predictions\n",
    "    Output: \n",
    "    yhat_pred        predicted observations\n",
    "    Sigma_Yhat_pred  covariance matrix of predicted observations\n",
    "    \"\"\"\n",
    "    yhat_pred = A_pred @ xhat\n",
    "    Sigma_Yhat_pred = A_pred @ Sigma_Xhat @ A_pred.T\n",
    "    return yhat_pred, Sigma_Yhat_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd261974",
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def conf_interval(yhat, Sigma_Yhat, conf_level):\n",
    "    \"\"\" \n",
    "    Function to calculate confidence interval of fitted model\n",
    "    conf_level is the confidence level as percentage (e.g., 95)\n",
    "    Output: \n",
    "    CI_yhat  confidence bound of yhat \n",
    "    k        CI_yhat[i] = k * sigma_yhat[i]\n",
    "    \"\"\"\n",
    "    alpha = 1 - conf_level/100\n",
    "    k = norm.ppf(1-0.5*alpha)\n",
    "    CI_yhat = k * np.sqrt(np.diagonal(Sigma_Yhat))\n",
    "    return CI_yhat, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1236d97-38d8-4b1e-b1bb-cf387658e35f",
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_all(t, y, A, t_pred, A_pred, sigma, conf_level_1, conf_level_2):\n",
    "    \"\"\" \n",
    "    Function to create plot with observations, fitted model \n",
    "    and confidence bounds (for 2 different confidence levels)\n",
    "    \"\"\"\n",
    "    m = len(t)\n",
    "    Sigma_Y = sigma**2*np.eye(m) \n",
    "    xhat, Sigma_Xhat, yhat = BLUE(A, y, Sigma_Y)\n",
    "    yhat_pred, Sigma_Yhat_pred = BLUE_predict(A_pred, xhat, Sigma_Xhat)\n",
    "    CI_yhat_1, k_1 = conf_interval(yhat_pred, Sigma_Yhat_pred, conf_level_1)\n",
    "    CI_yhat_2, k_2 = conf_interval(yhat_pred, Sigma_Yhat_pred, conf_level_2)\n",
    "    \n",
    "    # create plot with observations, error bars and confidence intervals\n",
    "    plt.figure(figsize = (10,6))\n",
    "    plt.xlabel('t [s]')\n",
    "    plt.ylabel('x(t) [m]')\n",
    "\n",
    "    plt.plot(t, y, 'k*',\n",
    "             label=f'observations with {conf_level_1:.1f}% conf.')\n",
    "    plt.title('$m$='+str(m)+' and $\\sigma$='+str(sigma)+' [m]')\n",
    "\n",
    "    # plot observations with errorbars   \n",
    "    plt.errorbar(t, y, yerr = k_1*sigma,\n",
    "                 fmt='', capsize=5, linestyle='')\n",
    "\n",
    "    # plot model and predicted observations\n",
    "    plt.plot(t, yhat, 'go')\n",
    "\n",
    "    # plot 95% confidence intervals\n",
    "    plt.plot(t_pred, yhat_pred + CI_yhat_1, 'r',\n",
    "             label=f'{conf_level_1:.1f}% conf.')\n",
    "    plt.plot(t_pred, yhat_pred - CI_yhat_1, 'r')\n",
    "\n",
    "    # plot 99% confidence intervals\n",
    "    plt.plot(t_pred, yhat_pred, 'g')\n",
    "    plt.plot(t_pred, yhat_pred + CI_yhat_2, 'r:',\n",
    "             label=f'{conf_level_2:.1f}% conf.')\n",
    "    plt.plot(t_pred, yhat_pred - CI_yhat_2, 'r:')\n",
    "\n",
    "    plt.ylim(-2, 20)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554947b",
   "metadata": {},
   "source": [
    "## Plot observations and confidence intervals (95% and 99%) with all observations\n",
    "You can also try different confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default model\n",
    "plot_all(t, y, A, t_pred, A_pred, sigma, 95, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1bb15f",
   "metadata": {},
   "source": [
    ":::{card}\n",
    "\n",
    "Explain the shape of the confidence bounds and the diffence between 95% and 99% confidence interval.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f28bc2",
   "metadata": {},
   "source": [
    " ```{admonition} Discussion\n",
    ":class: tip, dropdown\n",
    "\n",
    "* The 99% confidence interval is based on a larger probability that the observation error should be in the interval, so the interval will be wider. \n",
    "* Uncertainty in fitted line is due to uncertainty in estimated parameters: uncertainty in intercept manifests itself as a constant offset above and below the fitted line, the uncertainty in the slope implies uncertainty in the *angle*, which causes the widening towards the start and end.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde24f0b",
   "metadata": {},
   "source": [
    "## What if we reduce the number of observations (only the central 10)\n",
    "You can also try to select a different (e.g., even shorter) time range by selecting a subset of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a10e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2 = t[5:15]\n",
    "y_2 = y[5:15]\n",
    "A_2 = np.hstack((np.ones((len(t_2),1)),t_2))\n",
    "\n",
    "plot_all(t_2, y_2, A_2, t_pred, A_pred, sigma, 95, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ddf8e",
   "metadata": {},
   "source": [
    ":::{card}\n",
    "\n",
    "Compare with the first figure and discuss the differences.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2010d",
   "metadata": {},
   "source": [
    " ```{admonition} Discussion\n",
    ":class: tip, dropdown\n",
    "\n",
    "* Since we have a different set of observations, the estimates will be different.\n",
    "* With fewer observations, the precision will be worse, hence the wider confidence intervals.\n",
    "* Since all observations are in the centre, there is much more uncertainty in the predicted values outside the range of observation times.\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d81ba7",
   "metadata": {},
   "source": [
    "## What if we thought we had better precision (factor 2 better)\n",
    "\n",
    "**Note: in reality the precision of the observations is $\\sigma=2$m, so in fact this will show the confidence intervals based on an incorrect stochastic model.**\n",
    "\n",
    "We can investigate different precision by changing the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7af2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_wrong = 1\n",
    "plot_all(t, y, A, t_pred, A_pred, sigma_wrong , 95, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf26807",
   "metadata": {},
   "source": [
    ":::{card}\n",
    "\n",
    "Compare with the first figure.\n",
    "\n",
    "* The fitted line is the same, why is it not affected?\n",
    "* Discuss the differences in confidence intervals.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d66e58",
   "metadata": {},
   "source": [
    " ```{admonition} Discussion\n",
    ":class: tip, dropdown\n",
    "\n",
    "* Only if all observations are independent and have the same variance, the BLU estimate will be identical to the ordinary least-squares estimate (variance cancels). However, the precision will not be the same!\n",
    "* With (assumed) higher precision, the confidence intervals will be tighter (errors expected to be smaller).\n",
    "    \n",
    "Note again: in this case the assumed precision is too optimistic, which is visible since the fitted model does not go through many of the blue error bars.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62371d",
   "metadata": {},
   "source": [
    "## What if we have a different sampling interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_3 = np.vstack([7,8,8.5,9,9.5,10,10.5,11,11.5,12,13,\n",
    "                 13.5,14.5,15,15.5,16,16.5,17.5,18.5,19])\n",
    "A_3 = np.hstack((np.ones((len(t_3),1)),t_3))  \n",
    "\n",
    "plot_all(t_3, y, A_3, t_pred, A_pred, sigma, 95, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd662e7",
   "metadata": {},
   "source": [
    ":::{card}\n",
    "\n",
    "Compare with the first figure.\n",
    "\n",
    "* Discuss the differences. Especially compare the width of the confidence intervals at the centre and at the end of the time interval.\n",
    "* Is it better or not to have observations with smaller sampling interval?\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f7cc2",
   "metadata": {},
   "source": [
    " ```{admonition} Discussion\n",
    ":class: tip, dropdown\n",
    "\n",
    "* The number of observations is the same. The confidence interval in centre is tighter due to the smaller sampling interval, since here the the model is better constrained by the surrounding observations. However, outside the observation interval the uncertainty increases more rapidly.\n",
    "* Observations on a larger range of observation times will especially contribute to less uncertainty in the slope estimation, so would be favorable, especially if we want to make predicitions outside the observation interval.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383836f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Geen",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
