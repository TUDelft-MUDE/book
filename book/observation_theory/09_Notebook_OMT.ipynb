{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{custom_download_link} 09_Notebook_OMT.zip\n",
    ":text: \".zip (with data and solution)\"\n",
    ":replace_default: \"True\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook exercises: is my null hypothesis good enough?\n",
    "\n",
    "Click {fa}`rocket` --> {guilabel}`Live Code` on the top right corner of this screen and then wait until all cells are executed.\n",
    "\n",
    "If you want to download the notebook, select the .zip after clicking on {fa}`download`.\n",
    "\n",
    "In the following exercise, we will look at the curve fitting problem to a synthetic sea level rise dataset. The dataset contains yearly sea level measurements over 20 years (in total 20 observations). The time of observations are given in years as [1, 2, 3, ..., 20]. The observations are assumed to be normally distributed and have a precision of $\\sigma=2$ cm. The sea level at time zero is unknown and should also be estimated together with the other parameters. \n",
    "\n",
    "**In this exercise, we will:**\n",
    "1. Import the data,  create the design matrix $\\mathrm{A}$, and the covariance matrix $\\Sigma_Y$ (assuming the linear trend model).\n",
    "2. Apply BLUE and overall model test to check whether the null hypothesis (linear trend model) is sufficiently supported by the data.\n",
    "\n",
    "**We will look at 3 cases where the null-hypothesis is rejected:**\n",
    "1. Dataset is corrupted by one large outlier.\n",
    "2. We apply an incorrect functional model.\n",
    "3. We use a too optimistic value for the precision.  \n",
    "\n",
    "If we detect that the overall model test (i.e., our null hypothesis) is rejected, we would in practice need to apply the Generalized Likelihood Ratio test to test an alternative hypothesis against the null hypothesis, to decide whether it is sufficiently more likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def blue(A, y, Sigma_Y):\n",
    "    \"\"\"Calculate the estimates of the unknown parameters and the corresponding\n",
    "    covariance matrix using the BLUE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A: design matrix.\n",
    "    y: observations.\n",
    "    Sigma_Y: covariance matrix of the observables.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xhat: estimates of the unknown parameters.\n",
    "    Sigma_Xhat: covariance matrix of the estimates.\n",
    "    yhat: adjusted observations.\n",
    "    Sigma_Yhat: covariance matrix of adjusted observations.\n",
    "    e_hat: residuals.\n",
    "    Sigma_Ehat: covariance matrix of residuals.\n",
    "    \"\"\"\n",
    "\n",
    "    Sigma_Xhat = np.linalg.inv(A.T @ np.linalg.inv(Sigma_Y) @ A)\n",
    "    xhat = Sigma_Xhat @ A.T @ np.linalg.inv(Sigma_Y) @ y\n",
    "    \n",
    "    yhat = A @ xhat  \n",
    "    Sigma_Yhat = A @ Sigma_Xhat @ A.T\n",
    "    \n",
    "    e_hat = y - yhat\n",
    "    Sigma_Ehat = Sigma_Y - Sigma_Yhat\n",
    "    \n",
    "    return xhat, Sigma_Xhat, yhat, Sigma_Yhat, e_hat, Sigma_Ehat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def confidence_interval(conf_level, Sigma):\n",
    "    \"\"\"Calculate lower and upper bounds of the confidence interval.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    conf_level: confidence level (=1-alpha), e.g., 0.95.\n",
    "    Sigma: covariance matrix of the variable for which to calculate the\n",
    "             confidence interval.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cint: half of the width of the confidence interval.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    The lower and upper bounds of the confidence interval can be calculated as:\n",
    "    y_lower = y - cint\n",
    "    y_upper = y + cint\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = 1 - conf_level\n",
    "    k = norm.ppf(1 - alpha/2)\n",
    "    cint =  k * (np.sqrt(np.diagonal(Sigma)))\n",
    "\n",
    "    return cint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def overall_model_test(alpha, ehat, Sigma_Y, q):\n",
    "    \"\"\"Performs the overall model test and prints the outcome.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha: false alarm probability\n",
    "    ehat: residuals.\n",
    "    Sigma_Y: covariance matrix of the observables.\n",
    "    q: degrees of freedom of Chi2-distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    k = chi2.ppf(1 - alpha, q)\n",
    "    Tq = ehat.T @ np.linalg.inv(Sigma_Y) @ ehat\n",
    "    \n",
    "    if Tq < k:\n",
    "        print(f\"(T = {Tq:.1f}) < (K = {k:.1f}), OMT is accepted.\")\n",
    "    else:\n",
    "        print(f\"(T = {Tq:.1f}) > (K = {k:.1f}), OMT is rejected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_results(t, A, y, Sigma_Y, conf_level, alpha):#(t, y, yhat, yhat_int, ehat, ehat_int, conf_level, alpha):\n",
    "    \"\"\"Produce plots of the (adjusted) observations and the residuals,\n",
    "    including the confidence bounds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t: times.\n",
    "    y: observations.\n",
    "    A: design matrix.\n",
    "    Sigma_Y: covariance matrix of the observables.\n",
    "    conf_level: confidence level.\n",
    "    \"\"\"\n",
    "    \n",
    "    xhat, Sigma_Xhat, yhat, Sigma_Yhat, ehat, Sigma_Ehat = blue(A, y, Sigma_Y)\n",
    "    \n",
    "    yhat_int = confidence_interval(conf_level, Sigma_Yhat)\n",
    "    ehat_int = confidence_interval(conf_level, Sigma_Ehat)\n",
    "    \n",
    "    overall_model_test(alpha, ehat, Sigma_Y, len(y)-len(xhat))\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(t, y,'r.',markersize=15, label='observations')\n",
    "    plt.plot(t, yhat, linewidth=3, label='fitted model')\n",
    "    plt.plot(t, yhat-yhat_int, 'r--', linewidth=2,\n",
    "             label='{} % conf.'.format(conf_level*100))\n",
    "    plt.plot(t, yhat+yhat_int, 'r--', linewidth=2)\n",
    "    plt.grid()\n",
    "    plt.xlabel('time [years]')\n",
    "    plt.ylabel('Sea level [cm]')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(t, ehat, 'r.',markersize=15, label='residuals')\n",
    "    plt.plot(t, ehat_int, 'r--', linewidth=2,\n",
    "             label='{} % conf.'.format(conf_level*100))\n",
    "    plt.plot(t, - ehat_int, 'r--', linewidth=2)\n",
    "    plt.grid()\n",
    "    plt.xlabel('time [years]')\n",
    "    plt.ylabel('Residuals [cm]')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 0: linear trend model is correct\n",
    "\n",
    "First, import the data and compute the number of observations ```m```, vector with observation times ```t```, standard deviation of the measurements ```std_y```, covariance matrix of observations ```Sigma_Y```, design matrix ```A```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = np.genfromtxt('./data/Dataset_0.txt')\n",
    "m = len(y_0)\n",
    "t = np.arange(1,m+1)\n",
    "\n",
    "std_y = 2 \n",
    "Sigma_Y = std_y**2 * np.eye(m)\n",
    "A = np.column_stack((np.ones(m), t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <code>plot_results</code> will perform BLUE and the overall model test with a false alarm probability ```alpha```, and then plot results with confidence intervals with confidence level ```conf_level```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(t, A, y_0, Sigma_Y, conf_level = 0.95, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: linear trend model, outlier in data\n",
    "\n",
    "In Dataset_1 one of the observations is an outlier... We will apply BLUE and perform the overall model test with this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = np.genfromtxt('./data/Dataset_1.txt')\n",
    "plot_results(t, A, y, Sigma_Y, conf_level = 0.95, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} Question \n",
    "\n",
    "Why are more residuals negative in this case?\n",
    "\n",
    " ```{admonition} Answer\n",
    ":class: tip, dropdown\n",
    "\n",
    "The fitted line is pulled towards the large outlier, and therefore more observations will lie below.\n",
    "\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 2: linear trend model is too simplistic\n",
    "\n",
    "For Dataset_2 the linear trend model assumptions is not correct... We will apply BLUE and perform the overall model test with this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = np.genfromtxt('./data/Dataset_2.txt')\n",
    "plot_results(t, A, y_2, Sigma_Y, conf_level=0.95, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} Questions\n",
    "\n",
    "How can you see from the residuals plot that the linear model is too simplistic?\n",
    "\n",
    "What would be a better model? Try yourself by completing the code below.\n",
    "\n",
    " ```{admonition} Answers\n",
    ":class: tip, dropdown\n",
    "\n",
    "There is a clear 'non-random' pattern over time.\n",
    "    \n",
    "A second-order polynomial. You can try by inserting the corresponding $\\mathrm{A}$-matrix <code>A_2</code> in the next code cell.\n",
    "\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_2 = ?\n",
    "plot_results(t, A_2, y_2, Sigma_Y, conf_level=0.95, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```{admonition} Solution\n",
    ":class: tip, dropdown\n",
    "<code>A_2 = np.column_stack((np.ones(m), t, t**2))</code>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 3: linear trend model, too optimistic about precision\n",
    "\n",
    "The observations in Dataset_3 are less precise than before... We will apply BLUE and perform the overall model test with this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = np.genfromtxt('./data/Dataset_3.txt')\n",
    "plot_results(t, A, y_3, Sigma_Y, conf_level=0.95, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} Question \n",
    "\n",
    "How can you see that we were too optimistic about the precision of the observations? Play with the factor below to see if indeed the model is accepted if we choose a larger value for the precision.\n",
    "\n",
    " ```{admonition} Solution\n",
    ":class: tip, dropdown\n",
    "Much more than 5% of the residuals is outside the 95% confidence interval, which is determined by the assumed precision of 2 cm. If we would use <code>2 * Sigma_Y</code> we would see that the model is accepted (hence the precision should have been $2\\sqrt{2}$ cm).\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = ?\n",
    "plot_results(t, A, y_3, factor * Sigma_Y, conf_level=0.95, alpha = 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf78f3d1bc82cb39ac7a1165ed20acb9158792c8f97b380f92edad57bf927ea3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
